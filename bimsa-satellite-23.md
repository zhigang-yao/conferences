---
layout: default
title: The First Symposium of Geometry and Statistics
description: Yanqi Lake Beijing Institute of Mathematical Sciences and Applications, Yau Center at Tsinghua University <br> Beijing July 29 - 31, 2023

---
![tour](./pic/tour.jpg)

## General Information
 <p style="text-align:justify;">
 The purpose of the conference is to promote the research on the emerging field of interface of statistics and geometry among researchers in China and beyond. This is a continuous effort, following the recent <a href="https://cmsa.fas.harvard.edu/event/geometry-and-statistics/">Harvard conference on geometry and statistics</a>. Anyone who has received a Ph.D. or expects to receive a Ph.D. by the end of 2023 in the relevant field is eligible to attend. Participants from under-represented groups are especially encouraged to attend.
 </p>


 <p style="text-align:justify;">
The conference will take place at the <a href="https://www.bimsa.cn/">Yanqi Lake Beijing Institute of Mathematical Sciences and Applications (BIMSA)</a>, sponsored by BIMSA and the <a href="https://ymsc.tsinghua.edu.cn/en/">Yau Mathematical Sciences Center at Tsinghua University</a>, during July 29 - 31, 2023.
This conference is a satellite conference of the International Congress of Basic Science scheduled in Beijing during July 16 - 28, 2023.
 </p>

## Registration (<a href="https://zhigang-yao.github.io/group.jpg">Group photo</a>)

Register is closed.

## Invited speakers 
* Louis Christie (Cambridge)
* Ke Deng (Tsinghua)
* Scott V. Edwards (Harvard)
* Xinqi Gong (Renmin U)
* Yang-Hui He (London Institute for Mathematical Sciences)
* Stephan Huckemann (Georg-August-Universität Göttingen)
* Yongdai Kim (Seoul National U)
* Xiangdong Li (AMSS/CAS)
* Kefeng Liu (UCLA)
* Ezra Miller (Duke)
* Stefan Sommer (U of Copenhagen)
* Zaiwen Wen (Peking U)
* Hao Xu (Zhejiang U)
* Zhigang Yao (NUS/CMSA Harvard)
* Stephen Yau (Tsinghua)
* Chunming Zhang (UW Madison)
* Jian Zhang (U of Kent)


## Organizing Committee
* Rongling Wu (BIMSA)
* Lijian Yang (Tsinghua)
* [Zhigang Yao (NUS/Harvard CMSA and Committee Chair)](https://zhigang-yao.github.io/)

## Scientific Advisors: 
* Shiu-Yuen Cheng (Tsinghua)
* Shing-Tung Yau (Tsinghua)
  
## Contact Information
Scientific Aspects Enquiries: <a href="mailto:zhigang.yao@nus.edu.sg">zhigang.yao(AT)nus.edu.sg</a>

## Schedule (<a href="https://zhigang-yao.github.io/Schedule.pdf">PDF</a>)

<p><strong>Saturday, July 29, 2023 (Beijing Time)</strong></p>
<table width="720">
  <tbody>
    <tr>
      <td width="158">8:30-8:45 am</td>
      <td colspan="2" width="562">Check in at BIMSA</td>
    </tr>
    <tr>
      <td width="158">8:45–9:00 am</td>
      <td width="172">Zhigang Yao/Rongling Wu</td>
      <td width="391">Welcome Remarks</td>
    </tr>
    <tr>
      <td width="158"></td>
      <td colspan="2" width="562">Morning Session Chair: Zhigang Yao</td>
    </tr>
    <tr>
      <td width="158">9:00–10:00 am</td>
      <td width="172">Stephan Huckemann (Göttingen)</td>
      <td width="391">
        <strong>Title:</strong> The wald space for phylogenetic trees<br>
        <strong>Abstract:</strong> Most existing metrics between phylogenetic trees directly measure differences in topology and edge weights, and are unrelated to the models of evolution used to infer trees. We describe metrics which instead are based on distances between the probability models of discrete or continuous characters induced by trees. We describe how construction of information-based geodesics leads to the recently proposed wald space of phylogenetic trees. As a point set, it sits between the BHV space (Billera, Holmes and Vogtmann, 2001) and the edge-product space (Moulton and Steel 2004). It has a natural embedding into the space of positive definite matrices, equipped with the information geometry. Thus, singularities such as overlapping leaves are infinitely far away, proper forests, however, comprising the "BHV-boundary at infinity", are part of the wald space, adding boundary correspondences to groves (corresponding to orthants in the BHV space). In fact the wald space contracts to the complete disconnected forest. Further, it is a geodesic space, exhibiting the structure of a Whitney stratified space of type (A) where strata carry compatible Riemannian metrics. We explore some more geometric properties, but the full picture remains open. We conclude by identifying open problems, we deem interesting.
      </td>
    </tr>
    <tr>
      <td width="158">10:00–10:10 am</td>
      <td colspan="2" width="562">Break</td>
    </tr>
    <tr>
      <td width="158">10:10–11:10 am</td>
      <td width="172">Yang-Hui He (London Institute for Mathematical Sciences)</td>
      <td width="391">
        <strong>Title:</strong> AI for mathematics<br>
        <strong>Abstract:</strong> We summarize how AI can approach mathematics in three ways: theorem-proving, conjecture formulation, and language processing. Inspired by initial experiments in geometry and string theory, we present a number of recent experiments on how various standard machine-learning algorithms can help with pattern detection across disciplines ranging from algebraic geometry to representation theory, to combinatorics, and to number theory.
      </td>
    </tr>
    <tr>
      <td width="158">11:10–11:20 am</td>
      <td colspan="2" width="562">Break</td>
    </tr>
    <tr>
      <td width="158">11:20 am–12:20 pm</td>
      <td width="172">Zhigang Yao (NUS/Harvard CMSA)</td>
      <td width="391">
        <strong>Title:</strong> Random fixed boundary flows: a twin sister of principal flow?<br>
        <strong>Abstract:</strong> While classical statistics has dealt with observations which are real numbers or elements of a real vector space, nowadays many statistical problems of high interest in the sciences deal with the analysis of data which consist of more complex objects, taking values in spaces which are naturally not (Euclidean) vector spaces but which still feature some geometric structure. We consider fixed boundary flows with canonical interpretability as principal components extended on non-linear Riemannian manifolds. We aim to find a flow with fixed starting and ending points for noisy multivariate data sets lying near an embedded non-linear Riemannian manifold. In geometric terms, the fixed boundary flow is defined as an optimal curve that moves in the data cloud with two fixed end points. At any point on the flow, we maximize the inner product of the vector field, which is calculated locally, and the tangent vector of the flow. The rigorous definition is derived from an optimization problem using the intrinsic metric on the manifolds. For random data sets, we name the fixed boundary flow the random fixed boundary flow and analyze its limiting behavior under noisy observed samples. We show that the fixed boundary flow yields a concatenate of three segments, one of which coincides with the usual principal flow when the manifold is reduced to the Euclidean space. We further prove that the random fixed boundary flow converges largely to the population fixed boundary flow with high probability. Finally, we illustrate how the random fixed boundary flow can be used and interpreted, and demonstrate its application in real data sets.
      </td>
    </tr>
    <tr>
      <td width="158">12:20–1:50 pm</td>
      <td colspan="2" width="562">
        12:20 pm Group Photo<br>followed by Lunch
      </td>
    </tr>
    <tr>
      <td width="158"></td>
      <td colspan="2" width="562">Afternoon Session Chair: Ezra Miller</td>
    </tr>
    <tr>
      <td width="158">1:50–2:50 pm</td>
      <td width="172">Stephen Yau (Tsinghua)</td>
      <td width="391">
        <strong>Title:</strong> Grand Biological Universe: The geometric construction of genome space and its applications<br>
        <strong>Abstract:</strong> Imitating Hilbert who proposed 23 problems in mathematics in 1900, Defense Advanced Research Projects Agency (DARPA) proposed 23 problems in pure and applied mathematics in 2008. These problems will prove to be very influential for the development of mathematics in the 21st century. In the DARPA problems, we are asked to understand “The Geometry of Genome Space” (the number 15) and “What are the Fundamental Laws of Biology” (the number 23). Our convex hull principle for molecular biology states that the convex hull formed from Natural Vectors of one biological group does not intersect with the convex hull formed from any other biological group. This can be viewed as one of the Fundamental Laws of Biology for which DARPA has been looking for since 2008. On the basis of the convex hull principle, we can construct the geometry of the genome space. A genome space consists of all known genomes of living beings and provides insights into their relationships. The genome space can be considered as the moduli space in mathematics, and genome sequences can be canonically embedded in a high-dimensional Euclidean space by means of Natural Vectors. In this space, a sequence is uniquely represented as a point by the nucleotide distribution information of the sequence. Similar sequences lie closely, and convex hulls of different groups are disjoint according to the convex hull principle. The geometry of space is reflected in the similarity of sequences. The similarity of sequences can be measured by the Natural Metric, which is different from the induced metric from the ambient Euclidean space. Like our physical world, dark matter and dark energy play a crucial role in the construction of the correct Natural Metric in genome space. Our goal is to construct the genome spaces of seven kingdoms with Natural Metrics. These metrics are quite different in each genome space because different dark matter and dark energy may bend space-time as predicted by Einstein’s theory. As applications, we provide the first mathematical method to find undiscovered genome sequence. Our theory allows us to explore the phylogenetic relationships of biological sequences and where SARS-CoV-2 originated from. It provides a novel geometric perspective to study molecular biology. It also gives an accurate way for large-scale sequences comparison in real-time manner.
      </td>
    </tr>
    <tr>
      <td width="158">2:50–3:00 pm</td>
      <td colspan="2" width="562">Break</td>
    </tr>
    <tr>
      <td width="158">3:00–4:00 pm</td>
      <td width="172">Jian Zhang (U of Kent)</td>
      <td width="391">
        <strong>Title:</strong> Cross-Validated Estimation for Penalised Skew Normal and Beyond<br>
        <strong>Abstract:</strong> Skew normal model is often used in various scientific research fields in bioscience, business and finance studies. The skew normal distribution extends the normal distribution by including one more parameter called shape parameter, which is used to gauge the magnitude of skewness. However, the skew normal is a singular model; when the shape parameter is approaching zero, the corresponding Fisher information matrix fails to be invertible. This makes the standard maximum likelihood estimation ill-posed. The standard Bayesian information criterion may not work. Here, we address the problem by penalised likelihood estimation with penalty coefficient being determined by cross-validation. We show phase-transition behaviour of the cross-validated coefficient when the shape parameter is closing to zero. We establish a large sample theory for the penalised MLE. We evaluate the performance of the proposed method in multiple anti-cancer drug studies.
      </td>
    </tr>
    <tr>
      <td width="158">4:00–4:10 pm</td>
      <td colspan="2" width="562">Break</td>
    </tr>
    <tr>
      <td width="158">4:10–5:10 pm</td>
      <td width="172">Chunming Zhang (UW Madison)</td>
      <td width="391">
        <strong>Title:</strong> New Statistical Learning Method for Independent Component Analysis with Applications to Brain EEG<br>
        <strong>Abstract:</strong> Independent Component Analysis (ICA) is a widely used unsupervised learning method in medical imaging and signal processing, aimed at extracting non-Gaussian independent components (ICs) from multi-dimensional data. However, existing optimization methods often recover ICs from observed signals in unrealistic noiseless settings, with limited theoretical guarantees. We propose a new framework for "noisy ICA" that tackles this challenge from different perspectives, inspired by the desire to identify latent components resembling neural sources of cortical origin from electroencephalography (EEG) recordings of brain activity. Our approach not only directly estimates ICs but also enables the estimation of the unknown number of latent ICs. We have developed a computationally efficient algorithm that solves the non-convex and non-smooth optimization problem with guaranteed convergence. Furthermore, we prove that our estimator is consistent under mild conditions. Numerical simulations demonstrate that our approach outperforms existing methods. Finally, we apply our method to EEG data and show that it can reveal brain source signals with improved quantity and quality.
      </td>
    </tr>
  </tbody>
</table>


<p><strong>Sunday, July 30, 2023 (Beijing Time)</strong></p>
<table width="720">
  <tbody>
    <tr>
      <td width="148"></td>
      <td colspan="2" width="572">Morning Session Chair: Zhigang Yao</td>
    </tr>
    <tr>
      <td width="148">9:00-10:00 am</td>
      <td width="181">Ezra Miller (Duke)</td>
      <td width="391">
        <strong>Title:</strong> Geometry of measures on stratified spaces<br>
        <strong>Abstract:</strong> The central limit theorem (CLT) is commonly thought of as
        occurring on the real line, or in multivariate form on a
        real vector space.  Motivated by statistical applications
        involving nonlinear data, such as angles or phylogenetic
        trees, the past twenty years have seen CLTs proved for
        Fréchet means on manifolds and on certain examples of
        singular spaces built from flat pieces glued together in
        combinatorial ways. These CLTs reduce to the linear case
        by tangent space approximation or by gluing.  What should a
        CLT look like on general non-smooth spaces, where tangent
        spaces are not linear and no combinatorial gluing or flat
        pieces are available? This talk provides an overview of these answers,
        concluding with gateways this investigation opens to further advances
        in geometry, probability, topology, and statistics. Joint work with Jonathan Mattingly and Do Tran.
      </td>
    </tr>
    <tr>
      <td width="148">10:00-10:10 am</td>
      <td colspan="2" width="572">Break</td>
    </tr>
    <tr>
      <td width="148">10:10-11:10 am</td>
      <td width="181">Scott Edwards (Harvard)</td>
      <td width="391">
        <strong>Title:</strong> Bayesian inference of genome-phenotype associations using phylogenies and genome sequence data<br>
        <strong>Abstract:</strong> Connecting genotype and phenotype is of ongoing interest in evolutionary biology. Comparative genomics is now allowing us to map genes for traits using phylogenetic approaches (‘PhyloG2P’), which leverage phenotypically unique lineages or convergent evolution to provide surprisingly precise mapping of loci underlying evolutionarily labile traits. An example focusing on loss of flight in birds reveals a strong role for non-coding regulatory evolution in the origin of key adaptations of birds.
      </td>
    </tr>
    <tr>
      <td width="148">11:10-11:20 am</td>
      <td colspan="2" width="572">Break</td>
    </tr>
    <tr>
      <td width="148">11:20 am-12:20 pm</td>
      <td width="181">Xinqi Gong (Renming U)</td>
      <td width="391">
        <strong>Title:</strong> Geometry enhanced deep learning prediction of multibody protein interaction complex structures<br>
        <strong>Abstract:</strong> Improved from our dimer protein-protein docking methods, we have designed new geometry-enhanced deep learning algorithms to predict the interface residue pair in multibody protein complex structures. The procedure shows promise and advantages when tested on an experimental dataset.
      </td>
    </tr>
    <tr>
      <td width="148">12:20–1:50 pm</td>
      <td colspan="2" width="572">Lunch</td>
    </tr>
    <tr>
      <td width="148"></td>
      <td colspan="2" width="572">Afternoon Session Chair: Stephan Huckemann</td>
    </tr>
    <tr>
      <td width="148">1:50-2:50 pm</td>
      <td width="181">Stefan Sommer (U of Copenhagen)</td>
      <td width="391">
        <strong>Title:</strong> Diffusions means in geometric statistics<br>
        <strong>Abstract:</strong> Analysis and statistics of shape variation and manifold-valued data can be formulated probabilistically. This talk explores diffusion means and related algorithms.
      </td>
    </tr>
    <tr>
      <td width="148">2:50-3:00 pm</td>
      <td colspan="2" width="572">Break</td>
    </tr>
    <tr>
      <td width="148">3:00-4:00 pm</td>
      <td width="181">Yongdai Kim (SNU)</td>
      <td width="391">
        <strong>Title:</strong> On the use of the beta-VAE for learning probabilistic generative models<br>
        <strong>Abstract:</strong> Probabilistic generative models such as VAE and GAN have seen much attention. This talk considers the beta-VAE and derives the convergence rate under regularity conditions, showing that it may be more appropriate for learning probabilistic models.
      </td>
    </tr>
    <tr>
      <td width="148">4:00-5:10 pm</td>
      <td colspan="2" width="572">Break</td>
    </tr>
    <tr>
      <td width="148">4:10-5:00 pm</td>
      <td width="181">Zaiwen Wen (Peking U)</td>
      <td width="391">
        <strong>Title:</strong> A Monte Carlo Policy Gradient Method with Local Search for Binary Optimization<br>
        <strong>Abstract:</strong> Binary integer programming problems are NP-hard. In this talk, we present a policy gradient method using deep Monte Carlo local search for binary optimization problems.
      </td>
    </tr>
  </tbody>
</table>



<p><strong>Monday, July 31, 2023 (Eastern Time)</strong></p>
<table width="720">
  <tbody>
    <tr>
      <td width="156"></td>
      <td colspan="2" width="564">Morning Session Chair: Zhigang Yao</td>
    </tr>
    <tr>
      <td width="156">9:00-10:00 am</td>
      <td width="173">Hao Xu (Zhejiang U) and Kefeng Liu (UCLA)</td>
      <td width="391">
        <strong>Title:</strong> Frobenius algebra structure of statistical manifold<br>
        <strong>Abstract:</strong> In information geometry, a statistical manifold is a Riemannian manifold (M,g) equipped with a totally symmetric (0,3)-tensor. We show that the tangent bundle of a statistical manifold has a Frobenius algebra structure if and only if the sectional K-curvature vanishes. This gives a statistical-geometric curvature interpretation for WDVV equation and thus solving for constant sectional K-curvature becomes a natural generalization of the WDVV equation. We also study natural statistical structures on the tangent bundle of a statistical manifold and give a new proof of Alekseevsky-Cortes' geometric construction of r-maps that associates a special real manifold to a special Kahler manifold.
      </td>
    </tr>
    <tr>
      <td width="156">10:00-10:10 am</td>
      <td colspan="2" width="564">Break</td>
    </tr>
    <tr>
      <td width="156">10:10-11:10 am</td>
      <td width="173">Xiangdong Li (AMSS/CAS)</td>
      <td width="391">
        <strong>Title:</strong> Optimal transport problem and random matrices theory<br>
        <strong>Abstract:</strong> In 1776, G. Monge raised the optimal transport problem from the study of military engineering problems. In 1939, L. Kantorovich reformulated the optimal transport problem and used it to study the optimal allocation problem. In 1975, Kantorovich shared the Nobel prize for economics with T. Koopmans "for their contribution to the optimal allocation of scarce resources." In 1992, Y. Brenier solved the optimal transport problem with quadratic distance cost function. Since then, the optimal transport problem has received a lot of attention both from theoretical and applied mathematics. In this talk, I will give a short survey on the history of the optimal transport problem, and then present our recent work in the study of random matrix theory using the approach from the optimal transport problem.
      </td>
    </tr>
    <tr>
      <td width="156">11:10-11:20 am</td>
      <td colspan="2" width="564">Break</td>
    </tr>
    <tr>
      <td width="156">11:20 am-12:20 pm</td>
      <td width="173">Ke Deng (Tsinghua)</td>
      <td width="391">
        <strong>Title:</strong> TBA<br>
        <strong>Abstract:</strong> TBA
      </td>
    </tr>
    <tr>
      <td width="156">12:20-1:50 pm</td>
      <td colspan="2" width="564">Lunch</td>
    </tr>
    <tr>
      <td width="156"></td>
      <td colspan="2" width="564">Afternoon Session Chair: Ezra Miller</td>
    </tr>
    <tr>
      <td width="156">1:50-2:50 pm</td>
      <td width="173">Stephan Huckemann (Göttingen)</td>
      <td width="391">
        <strong>Title:</strong> Statistical Challenges in Shape Prediction of Biomolecules<br>
        <strong>Abstract:</strong> The three-dimensional / higher-order structure of biomolecules determines their functionality. While assessing their primary structure is fairly accessible, reconstruction of the higher order structure is costly. We describe a purely statistical method, learning error correction, drawing power from a two-scale approach. We validate this method by comparison to reconstructions obtained from simulations approximating biophysical chemistry, illustrated by the RNA example of SARS-CoV-2. Joint work with Benjamin Eltzner, Kanti V. Mardia, and Henrik Wiechers.
      </td>
    </tr>
    <tr>
      <td width="156">2:50-3:00 pm</td>
      <td colspan="2" width="564">Break</td>
    </tr>
    <tr>
      <td width="156">3:00-4:00 pm</td>
      <td width="173">Louis Christie (Cambridge)</td>
      <td width="391">
        <strong>Title:</strong> Estimating Maximal Symmetries of Regression Functions<br>
        <strong>Abstract:</strong> We present a method to estimate the symmetries of non-parametric regression functions. Symmetry estimation is carried out using hypothesis testing for invariance strategically over the subgroup lattice of a search group G acting on the feature space. We demonstrate the performance of this estimator in synthetic settings and apply the methods to an application using satellite measurements of the Earth's magnetic field.
      </td>
    </tr>
    <tr>
      <td width="156">4:00-4:10 pm</td>
      <td width="173">Zhigang Yao</td>
      <td width="391">Closing Remarks</td>
    </tr>
  </tbody>
</table>



## Sponsors
<!-- ![yanqi](./pic/yanqi_small.png)
![ymsc](./pic/yanqi_small.png) -->

<table>
<tr>
<td><img src="./pic/yanqi_small.png" alt="yanqi"></td>
<td><img src="./pic/YMSC_small.png" alt="ymsc"></td>
</tr>
</table>
